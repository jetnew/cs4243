{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72333208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import time\n",
    "import utils\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232e64ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages (4.64.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c37589e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data.dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from losses import compute_contrastive_loss_from_feats\n",
    "from utils import *  # bad practice, nvm\n",
    "from models import *\n",
    "\n",
    "# from dataset import ImageDataset\n",
    "from training_config import doodles, reals, doodle_size, real_size, NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a27e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = 'exp_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ad48234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_dataset(datasets, size):\n",
    "    combined_dataset = {}\n",
    "    for name, dataset in datasets.items():\n",
    "        for class_name, class_data in dataset.items():\n",
    "            if class_name not in combined_dataset:\n",
    "                combined_dataset[class_name] = []\n",
    "            # resize data so they can be stacked\n",
    "            resized = []\n",
    "            for data in class_data:\n",
    "                resized.append(cv2.resize(data, (size, size), interpolation=cv2.INTER_AREA))\n",
    "            resized = np.stack(resized, axis=0)\n",
    "            combined_dataset[class_name].append(resized)\n",
    "    for class_name, lst_datasets in combined_dataset.items():\n",
    "        combined_dataset[class_name] = np.concatenate(lst_datasets, axis=0)\n",
    "    return combined_dataset\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    DATASET_DIR = {True: 'dataset/dataset_train.npy', False: 'dataset/dataset_test.npy'}\n",
    "\n",
    "    def __init__(self, doodles_list, real_list, doodle_size, real_size, train: bool):\n",
    "        super(ImageDataset, self).__init__()\n",
    "\n",
    "        dataset = np.load(self.DATASET_DIR[train], allow_pickle=True)[()]\n",
    "\n",
    "        doodle_datasets = {name: data for name, data in dataset.items() if name in doodles_list}\n",
    "        real_datasets = {name: data for name, data in dataset.items() if name in real_list}\n",
    "        self.doodle_dict = combined_dataset(doodle_datasets, doodle_size)\n",
    "        self.real_dict = combined_dataset(real_datasets, real_size)\n",
    "\n",
    "        # sanity check\n",
    "        assert set(self.doodle_dict.keys()) == set(self.real_dict.keys()), \\\n",
    "            f'doodle and real images label classes do not match'\n",
    "\n",
    "        # process classes\n",
    "        label_idx = {}\n",
    "        for key in self.doodle_dict.keys():\n",
    "            if key not in label_idx:\n",
    "                label_idx[key] = len(label_idx)\n",
    "        self.label_idx = label_idx\n",
    "\n",
    "        # parse data and labels\n",
    "        self.doodle_data, self.doodle_label = self._return_x_y_pairs(self.doodle_dict, label_idx)\n",
    "        self.real_data, self.real_label = self._return_x_y_pairs(self.real_dict, label_idx)\n",
    "\n",
    "        # data preprocessing\n",
    "        self.doodle_preprocess = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(doodle_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((self.doodle_data/255).mean(), (self.doodle_data/255).std())   # IMPORTANT / 255\n",
    "        ])\n",
    "\n",
    "        self.real_preprocess = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(real_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((self.real_data/255).mean(axis=(0, 1, 2)), (self.real_data/255).std(axis=(0, 1, 2)))\n",
    "        ])\n",
    "\n",
    "        print(f'Train = {train}. Doodle list: {doodles_list}, \\n real list: {real_list}. \\n classes: {label_idx.keys()} \\n'\n",
    "              f'Doodle data size {len(self.doodle_data)}, real data size {len(self.real_data)}, '\n",
    "              f'ratio {len(self.doodle_data)/len(self.real_data)}')\n",
    "\n",
    "    def _return_x_y_pairs(self, data_dict, category_mapping):\n",
    "        xs, ys = [], []\n",
    "        for key in data_dict.keys():\n",
    "            data = data_dict[key]\n",
    "            labels = [category_mapping[key]] * len(data)\n",
    "            xs.append(data)\n",
    "            ys.extend(labels)\n",
    "        return np.concatenate(xs, axis=0), np.array(ys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # naive sampling scheme - sample with replacement\n",
    "        # sample label first so that doodle and real data belong to the same category\n",
    "        label = random.choice(list(self.label_idx.keys()))\n",
    "        doodle_data = self.doodle_preprocess(random.choice(self.doodle_dict[label]))\n",
    "        real_data = self.real_preprocess(random.choice(self.real_dict[label]))\n",
    "        numer_label = self.label_idx[label]\n",
    "        return doodle_data, numer_label, real_data, numer_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.doodle_data), len(self.real_data)) # could be arbitrary number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fbf2180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convbn(in_channels, out_channels, kernel_size, stride, padding, bias):\n",
    "#     return nn.Sequential(\n",
    "#         nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "#         nn.BatchNorm2d(out_channels),\n",
    "#         nn.ReLU(inplace=True)\n",
    "#     )\n",
    "\n",
    "# class V2ConvNet(nn.Module):\n",
    "#     CHANNELS = [64, 128, 192, 256, 512]\n",
    "#     POOL = (1, 1)\n",
    "\n",
    "#     def __init__(self, in_c, num_classes, dropout=0.2, add_layers=False):\n",
    "#         super().__init__()\n",
    "#         layer1 = convbn(in_c, self.CHANNELS[1], kernel_size=3, stride=2, padding=1, bias=True)\n",
    "#         layer2 = convbn(self.CHANNELS[1], self.CHANNELS[2], kernel_size=3, stride=2, padding=1, bias=True)\n",
    "#         layer3 = convbn(self.CHANNELS[2], self.CHANNELS[3], kernel_size=3, stride=2, padding=1, bias=True)\n",
    "#         layer4 = convbn(self.CHANNELS[3], self.CHANNELS[4], kernel_size=3, stride=2, padding=1, bias=True)\n",
    "#         pool = nn.AdaptiveAvgPool2d(self.POOL)\n",
    "#         self.layers = nn.Sequential(layer1, layer2, layer3, layer4, pool)\n",
    "\n",
    "#         if add_layers:\n",
    "#             layer1_2 = convbn(self.CHANNELS[1], self.CHANNELS[1], kernel_size=3, stride=1, padding=0, bias=True)\n",
    "#             layer2_2 = convbn(self.CHANNELS[2], self.CHANNELS[2], kernel_size=3, stride=1, padding=0, bias=True)\n",
    "#             layer3_2 = convbn(self.CHANNELS[3], self.CHANNELS[3], kernel_size=3, stride=1, padding=0, bias=True)\n",
    "#             layer4_2 = convbn(self.CHANNELS[4], self.CHANNELS[4], kernel_size=3, stride=1, padding=0, bias=True)\n",
    "#             self.layers = nn.Sequential(layer1, layer1_2, layer2, layer2_2, layer3, layer3_2, layer4, layer4_2, pool)\n",
    "\n",
    "#         self.nn = nn.Linear(self.POOL[0] * self.POOL[1] * self.CHANNELS[4], num_classes)\n",
    "#         self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "#     def forward(self, x, return_feats=False):\n",
    "#         feats = self.layers(x).flatten(1)\n",
    "#         x = self.nn(self.dropout(feats))\n",
    "\n",
    "#         if return_feats:\n",
    "#             return x, feats\n",
    "\n",
    "#         return x\n",
    "\n",
    "class V2ConvNet(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, num_classes=9):\n",
    "        super(V2ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "        \n",
    "        self.lin1 = nn.Linear(256, 128)\n",
    "        self.lin2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x, return_feats=False):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        feats = self.relu(out)\n",
    "        \n",
    "        x = out.view(out.size(0), 256, -1).mean(2) # global average pooling\n",
    "        \n",
    "        x = self.lin1(x)\n",
    "        pred = self.lin2(x)\n",
    "        \n",
    "        if return_feats:\n",
    "            return pred, feats\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53f89931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(100, 3, 64, 64)\n",
    "net = V2ConvNet(3, 64, num_classes=9)\n",
    "y = net(x)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2fed255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model1, model2, train_set, val_set, tqdm_on, id, num_epochs, batch_size, learning_rate, c1, c2, t):\n",
    "    # cuda side setup\n",
    "    model1 = nn.DataParallel(model1).cuda()\n",
    "    model2 = nn.DataParallel(model2).cuda()\n",
    "\n",
    "    # training side\n",
    "    optimizer = torch.optim.AdamW(params=list(model1.parameters()) + list(model2.parameters()),\n",
    "                                  lr=learning_rate, weight_decay=3e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    # load the training data\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=16, pin_memory=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=16,\n",
    "                            pin_memory=True, drop_last=True)\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        loss1_model1 = AverageMeter()\n",
    "        loss1_model2 = AverageMeter()\n",
    "        loss2_model1 = AverageMeter()\n",
    "        loss2_model2 = AverageMeter()\n",
    "        loss3_combined = AverageMeter()\n",
    "        acc_model1 = AverageMeter()\n",
    "        acc_model2 = AverageMeter()\n",
    "\n",
    "        model1.train()\n",
    "        model2.train()\n",
    "        pg = tqdm(train_loader, leave=False, total=len(train_loader), disable=not tqdm_on)\n",
    "        for i, (x1, y1, x2, y2) in enumerate(pg):\n",
    "            # doodle, label, real, label\n",
    "            x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "\n",
    "            # train model1 (doodle)\n",
    "            pred1, feats1 = model1(x1, return_feats=True)\n",
    "            loss_1 = criterion(pred1, y1)    # classification loss\n",
    "            loss1_model1.update(loss_1)\n",
    "            loss_model1 = loss_1\n",
    "\n",
    "            # train model2 (real)\n",
    "            pred2, feats2 = model2(x2, return_feats=True)\n",
    "            loss_1 = criterion(pred2, y2)   # classification loss\n",
    "            loss1_model2.update(loss_1)\n",
    "            loss_model2 = loss_1\n",
    "\n",
    "            loss = loss_model1 + loss_model2\n",
    "\n",
    "            # statistics\n",
    "            acc_model1.update(compute_accuracy(pred1, y1))\n",
    "            acc_model2.update(compute_accuracy(pred2, y2))\n",
    "\n",
    "            # optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # display\n",
    "            pg.set_postfix({\n",
    "                'acc 1': '{:.6f}'.format(acc_model1.avg),\n",
    "                'acc 2': '{:.6f}'.format(acc_model2.avg),\n",
    "                'l1m1': '{:.6f}'.format(loss1_model1.avg),\n",
    "                'l1m2': '{:.6f}'.format(loss1_model2.avg),\n",
    "                'train epoch': '{:03d}'.format(epoch)\n",
    "            })\n",
    "\n",
    "        print(\n",
    "            f'train epoch {epoch}, acc 1={acc_model1.avg:.3f}, acc 2={acc_model2.avg:.3f}, l1m1={loss1_model1.avg:.3f}, 'f'l1m2={loss1_model2.avg:.3f}')\n",
    "\n",
    "        # validation\n",
    "        model1.eval(), model1.eval()\n",
    "        acc_model1.reset(), acc_model2.reset()\n",
    "        pg = tqdm(val_loader, leave=False, total=len(val_loader), disable=not tqdm_on)\n",
    "        with torch.no_grad():\n",
    "            for i, (x1, y1, x2, y2) in enumerate(pg):\n",
    "                pred1, feats1 = model1(x1, return_feats=True)\n",
    "                pred2, feats2 = model2(x2, return_feats=True)\n",
    "                acc_model1.update(compute_accuracy(pred1, y1))\n",
    "                acc_model2.update(compute_accuracy(pred2, y2))\n",
    "\n",
    "                # display\n",
    "                pg.set_postfix({\n",
    "                    'acc 1': '{:.6f}'.format(acc_model1.avg),\n",
    "                    'acc 2': '{:.6f}'.format(acc_model2.avg),\n",
    "                    'val epoch': '{:03d}'.format(epoch)\n",
    "                })\n",
    "\n",
    "        print(f'validation epoch {epoch}, acc 1 (doodle) = {acc_model1.avg:.3f}, acc 2 (real) = {acc_model2.avg:.3f}')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f'training finished')\n",
    "\n",
    "    # save checkpoint\n",
    "    exp_dir = f'exp_data/{id}'\n",
    "    save_model(exp_dir, f'{id}_model1.pt', model1)\n",
    "    save_model(exp_dir, f'{id}_model2.pt', model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "162e2388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d823d901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train = True. Doodle list: ['sketchy_doodle', 'tuberlin', 'google_doodles'], \n",
      " real list: ['sketchy_real', 'google_real', 'cifar']. \n",
      " classes: dict_keys(['airplane', 'car', 'cat', 'dog', 'frog', 'horse', 'truck', 'bird', 'ship']) \n",
      "Doodle data size 7022, real data size 46364, ratio 0.15145371408851696\n",
      "Train = False. Doodle list: ['sketchy_doodle', 'tuberlin', 'google_doodles'], \n",
      " real list: ['sketchy_real', 'google_real', 'cifar']. \n",
      " classes: dict_keys(['airplane', 'car', 'cat', 'dog', 'frog', 'horse', 'truck', 'bird', 'ship']) \n",
      "Doodle data size 1764, real data size 9341, ratio 0.18884487742211756\n"
     ]
    }
   ],
   "source": [
    "fix_seed(0)\n",
    "\n",
    "train_set = ImageDataset(doodles, reals, doodle_size, real_size, train=True)\n",
    "val_set = ImageDataset(doodles, reals, doodle_size, real_size, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd1529",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 0, acc 1=0.177, acc 2=0.261, l1m1=2.256,l1m2=2.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 0, acc 1 (doodle) = 0.220, acc 2 (real) = 0.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 1, acc 1=0.280, acc 2=0.332, l1m1=1.872,l1m2=1.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 1, acc 1 (doodle) = 0.302, acc 2 (real) = 0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 2, acc 1=0.326, acc 2=0.387, l1m1=1.765,l1m2=1.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 2, acc 1 (doodle) = 0.358, acc 2 (real) = 0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 3, acc 1=0.343, acc 2=0.425, l1m1=1.719,l1m2=1.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 3, acc 1 (doodle) = 0.325, acc 2 (real) = 0.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 4, acc 1=0.355, acc 2=0.464, l1m1=1.683,l1m2=1.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 4, acc 1 (doodle) = 0.356, acc 2 (real) = 0.430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 5, acc 1=0.370, acc 2=0.497, l1m1=1.656,l1m2=1.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 5, acc 1 (doodle) = 0.327, acc 2 (real) = 0.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 6, acc 1=0.376, acc 2=0.513, l1m1=1.633,l1m2=1.328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 6, acc 1 (doodle) = 0.369, acc 2 (real) = 0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 7, acc 1=0.387, acc 2=0.538, l1m1=1.601,l1m2=1.273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 7, acc 1 (doodle) = 0.351, acc 2 (real) = 0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 8, acc 1=0.396, acc 2=0.550, l1m1=1.588,l1m2=1.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 8, acc 1 (doodle) = 0.386, acc 2 (real) = 0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 9, acc 1=0.401, acc 2=0.571, l1m1=1.576,l1m2=1.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 9, acc 1 (doodle) = 0.369, acc 2 (real) = 0.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 10, acc 1=0.415, acc 2=0.575, l1m1=1.542,l1m2=1.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 10, acc 1 (doodle) = 0.382, acc 2 (real) = 0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 11, acc 1=0.420, acc 2=0.581, l1m1=1.533,l1m2=1.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 11, acc 1 (doodle) = 0.388, acc 2 (real) = 0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 12, acc 1=0.433, acc 2=0.599, l1m1=1.509,l1m2=1.120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 12, acc 1 (doodle) = 0.385, acc 2 (real) = 0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 13, acc 1=0.439, acc 2=0.597, l1m1=1.496,l1m2=1.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch 13, acc 1 (doodle) = 0.408, acc 2 (real) = 0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|▋| 66/90 [00:35<00:11,  2.03it/s, acc 1=0.440607, acc 2=0.598455, l1m1=1.498335, l1m2=1.11"
     ]
    }
   ],
   "source": [
    "# tunable hyper params.\n",
    "use_cnn = True\n",
    "num_epochs, base_bs, base_lr = 15, 512, 2e-2\n",
    "c1, c2, t = 0, 0, 0.1  # contrastive learning. if you want vanilla (cross-entropy) training, set c1 and c2 to 0.\n",
    "dropout = 0.3\n",
    "\n",
    "# models\n",
    "doodle_model = V2ConvNet(1, 64, num_classes=9)\n",
    "real_model = V2ConvNet(3, 64, num_classes=9)\n",
    "\n",
    "# just some logistics\n",
    "tqdm_on = True     # progress bar\n",
    "id = 25             # change to the id of each experiment accordingly\n",
    "\n",
    "train_model(doodle_model, real_model, train_set, val_set, tqdm_on, id, num_epochs, base_bs, base_lr, c1, c2, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f160b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
